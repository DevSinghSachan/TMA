Hi all,
I wanted to let everyone know about some work we've just presented at KDD
on applications of topic modeling. You can read our paper here:
http://www.cs.umass.edu/~mimno/papers/frp806-mimno.pdf
(Expertise Modeling for Matching Papers with Reviewers, David Mimno and
Andrew McCallum)
The idea is to understand people's areas of expertise by analyzing their
previously published work. In this case the data was computer science
publications and the task was matching reviewers with papers submitted to
a conference.
We compare some unigram language models used in information retrieval with
two topic models:
* an author-topic model in which all of a given author's papers are
generated from a single topic multinomial
* a new author-persona-topic model in which each author has some number of
topic multinomials ("personas"), and each paper is generated by one of the
personas
We train both topic models with Gibbs sampling. In the APT model, we
alternate between sampling hidden topics given the persona and sampling a
persona for each document given the sampled topics.
To evaluate the models, we took accepted papers from NIPS and calculated a
likelihood for each paper and author in each of the models. We pooled the
top reviewers for each model, and presented the union of those sets to
prominent NIPS researchers, who ranked each proposed reviewers as "not
relevant", "somewhat relevant", "relevant" and "very relevant".
We found that if we looked at precision after retrieving five reviewers
the language models did well, but as we retrieved more reviewers, the
topic models had higher precision. The intuition seems to be that the
topic models were able to find reviewers who didn't necessarily use
the exact words in the query document, but used words that were topically
related to the query.
-David
