Hi all,
I hope that everything is going very well. I am currently working on a question-answering project, and we need to cluster pairs of questions-answers (each question is at most one line, and each answer is one line too) based on their semantic contents. As a solution, I'm thinking of using topic modeling to extract topics, and cluster the pairs according to that. However, I am not sure in this case what a reasonable document-size/topic-size would be. If I put a large number of question-answers in a document, then the document will probably be a mixture of a lot of topics (almost all-topics), which will be problematic. Does it make sense to make each individual question-answer pair a topic? I can also cluster the question-answer pairs using some other clustering method (based on IR measures for instance), and then say each cluster is a document, but then the results will be biased because of the original clustering algotihm. So I'm wondering if there is a better way for selecting the documents. Is there some related work tha I can be pointed to?
My second question is about using log normal distribution vs Dirichlet. When does it make sense to use log normal comparing to Dirichlet? In my case, the topics (the human interpretable topics) are highly uncorrelated (history, translation, geography etc), but I would appreciate if you let me know practically in a task like this whether a Dirichlet prior is preferable or a log normal prior. Thanks in advance!
Best,
