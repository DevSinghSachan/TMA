Dear all,
I ran into a confusion about the supervised topic model (D. Blei and J.
McAuliffe. NIPS 2007). Recently, I applied sLDA codes (downloaded from
http://www.cs.princeton.edu/~chongw/slda/) in my experiments with some
toy data. In the toy data, each class only use its unique words, i.e.,
class 1 only uses words 0~199, class 2 only uses words 200~399...... The
total number of classes is 25 and every class has 100 documents. In
addition, each word in a document is generated by a same normal
distribution ~ N(200, 10) - the mean of the normal distribution is 200
and deviation is 10. (I have enclosed all my training data and results).
I estimated models and inferred using the same data, and I was expected
these "perfect" data for sLDA to get 100% inference accuracy. However,
in my experiments, the inference accuracy was only 84%, which means
there are 4 classes are wrongly inferred.
Could anyone tell why this happened? To me, it is confusing because that
all documents in a class only use the unique words and there is no word
overlapping across classes. Why isn't the inference result 100%
accurate? Thank you very much.
David
